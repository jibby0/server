# TODO move to the main helm values
apiVersion: ceph.rook.io/v1
kind: CephFilesystem
metadata:
  name: media2
  namespace: rook-ceph
spec:
  metadataPool:
    replicated:
      size: 3
    deviceClass: ssd
    failureDomain: host
  dataPools:
    - name: default
      replicated:
        size: 3
      deviceClass: hdd
      failureDomain: host
    - name: erasurecoded
      erasureCoded:
        dataChunks: 2
        codingChunks: 1
      deviceClass: hdd
      failureDomain: host
  preserveFilesystemOnDelete: true
  metadataServer:
    activeCount: 1
    activeStandby: true
    placement:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: storage-node
              operator: In
              values:
              - "true"
      tolerations:
      - key: storage-node
        operator: Exists
    priorityClassName: system-cluster-critical
